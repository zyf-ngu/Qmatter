# Qmatter - AI大模型入门系列（笔记&代码）

跟着问题学，减少学习弯路，高效入门AI大模型。

- **视频课程链接**：https://space.bilibili.com/70431433?spm_id_from=333.1007.0.0
- **代码&笔记仓库**：https://github.com/zyf-ngu/Qmatter


## 系列定位
本系列以“跟着问题学”为核心，通过「笔记+代码」的形式，为AI大模型初学者提供清晰学习路标。内容覆盖从基础工具到实战项目的全流程，学完即可具备大模型入门所需的理论认知与实践能力。


## 学习框架
当前分为四大模块（后续持续更新），覆盖入门核心需求：

### 1. Python 基础与进阶
AI大模型开发核心语言，从“0.5基础”起步，侧重实战应用。
- Python 基础（掌握核心语法，能读/写基础代码）
  - 数据结构（列表、字典、元组等）
  - 函数定义与调用
  - 类与面向对象编程
- Python 实践进阶（适配大型项目，能读GitHub主流项目）
  - 多进程与多线程
  - 模块导入原理
  - 文件路径管理
  - 参数传递技巧
  - 上下文管理器（`with`语句）


### 2. PyTorch 框架学习
AI模型开发核心框架，聚焦“张量”核心概念。
- 张量的创建、运算与变换
- 模型输入输出的张量维度变化逻辑
- 常用API实战（如`torch.nn`模块）


### 3. AI 经典模型
建立AI基础认知，覆盖CV与NLP两大方向。
- 计算机视觉（CV）
  - 经典模型：LeNet、ResNet、Mask R-CNN
  - 配套知识：数据处理、损失函数、优化算法、反向传播原理
- 自然语言处理（NLP）
  - Transformer前核心模型：Word2Vec、RNN、LSTM
  - 核心目标：理解文本表示与序列建模逻辑


### 4. 大模型基础与实战
完成大模型入门，掌握原理、部署与微调能力。
- Transformer原理与代码实现（大模型核心）
- 经典大模型学习：BERT、GPT系列
- 模型部署：在线API调用 + 本地部署
- 模型微调与训练：基础调参技巧
- RAG实战项目（基于LangChain）
  - 文档处理与解析
  - 向量数据库管理
  - FastAPI接口开发
  - 搭建个人知识库系统


## 学习思路
遵循以下5点原则，提升学习效率：

1. **跟着问题学**  
   聚焦学习中真实问题（如“Transformer为何用自注意力？”），从问题拆解知识点，避免“知识诅咒”。欢迎在Issues/评论区提问题，共同完善。

2. **多动手敲代码**  
   仓库提供配套代码，建议逐行手动编写（勿复制粘贴），实操中暴露并解决问题，提升能力。

3. **温故而知新的重复**  
   对核心知识点（如Transformer、张量运算）反复回顾，用“苏轼八面受敌读书法”加深理解。

4. **定期做知识总结**  
   将零散知识点梳理成系统结构（如思维导图），便于记忆、应用与扩展。

5. **多输出检验成果**  
   输出是最好的学习：向他人讲解知识点、写补充笔记、提交代码PR，梳理知识的同时深化理解。


## 关于本系列的想法
1. **相信AI的价值**  
   AI将成为人类强大助手：提升信息处理效率、替代重复事务，让人类聚焦创造性工作。

2. **助力后来者，共同学习**  
   本系列不仅是分享，更是互助——你的问题与反馈，会帮助完善内容，形成良性循环。

3. **交流AI未来发展**  
   创造力源于思维碰撞，欢迎在评论区/仓库交流大模型应用场景与未来方向。


## 结语
本系列致力于创造“有价值、有意义”的学习内容，如有建议（补充知识点、优化代码等），欢迎通过以下方式反馈：
- 视频评论区留言  
- GitHub仓库提交Issues或PR  

一起开启AI大模型学习之旅！
