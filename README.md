Qmatter - AI 大模型入门系列（笔记 & 代码）
跟着问题学，减少学习弯路，高效入门 AI 大模型。

    视频课程链接：https://space.bilibili.com/70431433?spm_id_from=333.1007.0.0
    代码 & 笔记仓库：https://github.com/zyf-ngu/Qmatter

系列定位
本系列以 “跟着问题学” 为核心，通过笔记 + 代码的形式，为 AI 大模型初学者提供清晰的学习路标。内容覆盖从基础工具到实战项目的全流程，学完即可具备大模型入门所需的理论认知与实践能力。
学习框架
目前内容分为四大模块，覆盖入门核心需求，后续将持续更新补充。
1. Python 基础与进阶
AI 大模型开发的核心语言，从 “0.5 基础” 起步，侧重实战应用。

    Python 基础：掌握核心语法，能读懂 / 编写基础代码
        数据结构（列表、字典、元组等）
        函数定义与调用
        类与面向对象编程
    Python 实践进阶：适配大型项目开发，能读懂 GitHub 主流项目
        多进程与多线程
        模块导入原理
        文件路径管理
        参数传递技巧
        上下文管理器（with语句）

2. PyTorch 框架学习
AI 模型开发的核心框架，聚焦 “张量” 这一核心概念。

    张量的创建、运算与变换
    模型输入输出的张量维度变化逻辑
    框架常用 API 实战（如torch.nn模块）

3. AI 经典模型
建立人工智能基础认知，覆盖计算机视觉（CV）与自然语言处理（NLP）两大方向。

    计算机视觉（CV）：
        经典模型：LeNet、ResNet、Mask R-CNN
        配套知识：数据处理、损失函数、优化算法、反向传播原理
    自然语言处理（NLP）：
        Transformer 之前的核心模型：Word2Vec、RNN、LSTM
        核心目标：理解文本表示与序列建模的基本逻辑

4. 大模型基础与实战
完成大模型入门，掌握原理、部署与微调能力。

    Transformer 原理与代码实现（大模型核心基础）
    经典大模型学习：BERT、GPT 系列
    模型部署：在线 API 调用 + 本地部署
    模型微调与训练：基础调参技巧与实践
    RAG 实战项目（基于 LangChain 框架）：
        文档处理与解析
        向量数据库管理
        FastAPI 接口开发
        搭建个人知识库管理系统

学习思路
遵循以下 5 点原则，可大幅提升学习效率与效果。

    跟着问题学

避免 “知识诅咒”，聚焦学习过程中真实遇到的问题（如 “为什么 Transformer 要用自注意力？”“张量维度为什么会变？”），从 “问题出发” 拆解知识点，确保理解透彻。
⚠️ 欢迎在仓库 Issues 或视频评论区提出你的问题，共同补充完善。
多动手敲代码
仓库提供配套代码，建议逐行手动编写（而非复制粘贴）。很多问题只有实际操作时才会暴露，解决过程即是能力提升的过程。
温故而知新的重复
采用 “苏轼八面受敌读书法”，对核心知识点（如 Transformer 原理、张量运算）反复回顾，每次重复都会有更深的理解。
定期做知识总结
将零散知识点梳理成系统性结构（如思维导图、笔记大纲），便于记忆、应用与后续扩展。
多输出，检验学习成果

    输出是最好的学习：
        向他人讲解知识点（能讲清即代表真理解）
        编写学习笔记（如本系列的补充笔记）
        提交代码 PR（参与仓库优化）

关于系列视频的想法

    相信 AI 的价值

AI 将成为人类的强大助手：提升海量信息处理效率、替代重复琐碎事务，让人类聚焦于创造性与思考性工作。
助力后来者，共同学习
本系列不仅是 “分享”，更是 “互助”—— 你的问题与反馈，会帮助我完善内容，形成良性循环。
交流 AI 未来发展
创造力源于思维碰撞，欢迎在评论区或仓库中交流大模型的应用场景与未来方向。

